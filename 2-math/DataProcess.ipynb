{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #数据预处理 Preprocessing & Impute \n",
    "# 2.1 数据无量纲化\n",
    "scaler = MinMaxScaler() \n",
    "result_ = scaler.fit_transform(data)\n",
    "scaler.inverse_transform(result) #将归一化后的结果逆转\n",
    "\n",
    "#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了\n",
    "#此时使用partial_fit作为训练接口\n",
    "#scaler = scaler.partial_fit(data)\n",
    "StandardScaler和MinMaxScaler选哪个？\n",
    "看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏\n",
    "感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。\n",
    "MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像\n",
    "处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。\n",
    "建议先试试看StandardScaler，效果不好换MinMaxScaler。\n",
    "除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广\n",
    "播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏\n",
    "性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选\n",
    "用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 缺失值\n",
    "# 机器学习和数据挖掘中所使用的数据，永远不可能是完美的。很多特征，对于分析和建模来说意义非凡，但对于实\n",
    "# 际收集数据的人却不是如此，因此数据挖掘之中，常常会有重要的字段缺失值很多，但又不能舍弃字段的情况。因\n",
    "# 此，数据预处理中非常重要的一项就是处理缺失值。\n",
    "\n",
    "data = pd.read_csv(r'Narrativedata.csv',index_col = 0 )\n",
    "data.head()\n",
    "data.info()\n",
    "#填补年龄\n",
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1) #sklearn当中特征矩阵必须是二维\n",
    "print(Age[:20])\n",
    "\n",
    "imp_mean = SimpleImputer() #实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\") #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补\n",
    "imp_mean = imp_mean.fit_transform(Age) #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)\n",
    "print(imp_mean[:20])\n",
    "print(imp_median[:20])\n",
    "print(imp_0[:20])\n",
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median\n",
    "data.info()\n",
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "imp_mode = SimpleImputer(strategy = \"most_frequent\")\n",
    "data.loc[:,\"Embarked\"] = imp_mode.fit_transform(Embarked)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值\n",
    "# 处理分类型特征：编码与哑变量\n",
    "y = data.iloc[:,-1] #要输入的是标签，不是特征矩阵，所以允许一维\n",
    "le = LabelEncoder() #实例化\n",
    "le = le.fit(y) #导入数据\n",
    "label = le.transform(y)   #transform接口调取结果\n",
    "print(le.classes_) #属性.classes_查看标签中究竟有多少类别\n",
    "print(label) #查看获取的结果label\n",
    "le.fit_transform(y) #也可以直接fit_transform一步到位\n",
    "le.inverse_transform(label) #使用inverse_transform可以逆转\n",
    "data.iloc[:,-1] = label #让标签等于我们运行出来的结果\n",
    "data.head()\n",
    "#如果不需要教学展示的话我会这么写：\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing.OrdinalEncoder：特征专用，能够将分类特征转换为分类数值\n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data_ = data.copy()\n",
    "data_.head()\n",
    "data_.info()\n",
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_\n",
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])\n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing.OneHotEncoder：独热编码，创建哑变量\n",
    "X = data.iloc[:,1:-1]\n",
    "enc = OneHotEncoder(categories='auto').fit(X)\n",
    "result = enc.transform(X).toarray()\n",
    "print(result)\n",
    "#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()\n",
    "#依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))\n",
    "enc.get_feature_names()\n",
    "print(result)\n",
    "print(result.shape)\n",
    "#axis=1,表示跨行进行合并，也就是将量表左右相连，如果是axis=0，就是将量表上下相连\n",
    "newdata = pd.concat([data,pd.DataFrame(result)],axis=1)\n",
    "newdata.head()\n",
    "newdata.drop([\"Sex\",\"Embarked\"],axis=1,inplace=True)\n",
    "newdata.columns = [\"Age\",\"Survived\",\"Female\",\"Male\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 处理连续型特征：二值化与分段\n",
    "data_2 = data.copy()\n",
    "X = data_2.iloc[:,0].values.reshape(-1,1) #类为特征专用，所以不能使用一维数组\n",
    "transformer = Binarizer(threshold=30).fit_transform(X)\n",
    "\n",
    "# preprocessing.KBinsDiscretizer\n",
    "# 这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0].values.reshape(-1,1) \n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit_transform(X)\n",
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "set(est.fit_transform(X).ravel())\n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "est.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择 feature_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
