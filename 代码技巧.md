## 1-python

将一个列表中所有的字符串连接

```
branch_name = ''.join([s[0] for s in value])
字典 defaultidict(int/str/list)  很爽

数据存储：
import  pickle
with open('son_fa.pickle','wb') as f:
    pickle.dump(res,f)
with open('son_fa.pickle','rb') as f:
    d1=pickle.load(f)
print(d1)
# 排序 key 按照我们想要的规则 
poi_list = sorted(poi_matched_list, key=lambda k: (k.get('distance')), reverse=False)
```

数据的读入： 不要一次读入所有的数据：

~~~
class MySentences(object):
    def __init__(self, dirname): # 	读入的目录 ， 
        self.dirname = dirname
    def __iter__(self):
        for fname in os.listdir(self.dirname): # 读入目录的所有文件， 每次读写一个文件的一行
            for line in open(os.path.join(self.dirname, fname)):
                yield line.split()
 
sentences = MySentences('/some/directory') # 第二种输入方式：占用内存少的迭代器
model = Word2Vec(sentences)
~~~





## 2-spl

select name ,kind ,address,new_kind
from poi  
where kind  in ('商务住宅' , '产业园区','公司企业','公司')
limit 10000

select name ,kind ,address,new_kind
from poi  
where kind like '%商务住宅%'  or kind like '%产业园区%' or kind like '%公司企业%' or kind like'%公司%'
limit 10000



```
labels = '100', '500', '1000', '1500','2000'
sizes = [18, 22, 7, 2,1]
explode = (0, 0.1, 0, 0.1,0)  # only "explode" the 2nd slice (i.e. 'Hogs')

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.savefig('Demo_official.jpg')
```

## 3-pandas 

~~~
df.read_excel(path, use_cols=[要选择的列])

~~~





Pd.concat(df1,df2 ,axis = 0) 合并两个dataframe

df.index. df.values 

df['column_name'].values_count()

```
删除某列的重复值
df = df.drop_duplicates("col_"name,keep='first').reset_index(drop=True) # 删除父子节点重复的值 
df_res['son_id'].unique()
set(df_res['son_id'])


```

df.rename(['old_name':new_name])

~~~
df.read_excle(path, keep_default_na = False ) 空格这没有内容 ，或者是NaN

df['col__naem'].value_counts() # 		统计该列重复值的个数 ， 
df.groupby('col_name')  # 返回的是 迭代器  fa[0]组的索引 fa[1] 数据 

const_cols = [c for c in df.columns if df[c].nunique(dropna=False)==1 ] # 某列只有一个值

对某一列进行处理 
df['column_name'].apply(lammada x : x+1 ) # 对某一列进行处理

#对最后1行进行插入
df_res.loc[df_res.shape[0]] = dict(zip(df_res.columns, res_rations))  # 将指标结构写入最后一行

~~~

## 4:  linux

Wc -l file  统计文件单词的数量

